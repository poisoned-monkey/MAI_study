{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_ML_2_1 (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZUBng4mkY5I"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "k4ao8XxUsZ8x",
        "outputId": "aa635ca5-159c-4a44-b1de-5eb070fefd3b"
      },
      "source": [
        "\n",
        "data = pd.read_csv('emails.csv')\n",
        "data.head(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email No.</th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "      <th>ect</th>\n",
              "      <th>and</th>\n",
              "      <th>for</th>\n",
              "      <th>of</th>\n",
              "      <th>a</th>\n",
              "      <th>you</th>\n",
              "      <th>hou</th>\n",
              "      <th>in</th>\n",
              "      <th>on</th>\n",
              "      <th>is</th>\n",
              "      <th>this</th>\n",
              "      <th>enron</th>\n",
              "      <th>i</th>\n",
              "      <th>be</th>\n",
              "      <th>that</th>\n",
              "      <th>will</th>\n",
              "      <th>have</th>\n",
              "      <th>with</th>\n",
              "      <th>your</th>\n",
              "      <th>at</th>\n",
              "      <th>we</th>\n",
              "      <th>s</th>\n",
              "      <th>are</th>\n",
              "      <th>it</th>\n",
              "      <th>by</th>\n",
              "      <th>com</th>\n",
              "      <th>as</th>\n",
              "      <th>from</th>\n",
              "      <th>gas</th>\n",
              "      <th>or</th>\n",
              "      <th>not</th>\n",
              "      <th>me</th>\n",
              "      <th>deal</th>\n",
              "      <th>if</th>\n",
              "      <th>meter</th>\n",
              "      <th>hpl</th>\n",
              "      <th>please</th>\n",
              "      <th>...</th>\n",
              "      <th>bold</th>\n",
              "      <th>catch</th>\n",
              "      <th>performing</th>\n",
              "      <th>accepted</th>\n",
              "      <th>matters</th>\n",
              "      <th>batch</th>\n",
              "      <th>continuing</th>\n",
              "      <th>winning</th>\n",
              "      <th>symbol</th>\n",
              "      <th>offsystem</th>\n",
              "      <th>decisions</th>\n",
              "      <th>produced</th>\n",
              "      <th>ended</th>\n",
              "      <th>greatest</th>\n",
              "      <th>degree</th>\n",
              "      <th>solmonson</th>\n",
              "      <th>imbalances</th>\n",
              "      <th>fall</th>\n",
              "      <th>fear</th>\n",
              "      <th>hate</th>\n",
              "      <th>fight</th>\n",
              "      <th>reallocated</th>\n",
              "      <th>debt</th>\n",
              "      <th>reform</th>\n",
              "      <th>australia</th>\n",
              "      <th>plain</th>\n",
              "      <th>prompt</th>\n",
              "      <th>remains</th>\n",
              "      <th>ifhsc</th>\n",
              "      <th>enhancements</th>\n",
              "      <th>connevey</th>\n",
              "      <th>jay</th>\n",
              "      <th>valued</th>\n",
              "      <th>lay</th>\n",
              "      <th>infrastructure</th>\n",
              "      <th>military</th>\n",
              "      <th>allowing</th>\n",
              "      <th>ff</th>\n",
              "      <th>dry</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Email 1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Email 2</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>95</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Email 3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Email 4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Email 5</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3002 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Email No.  the  to  ect  and  ...  military  allowing  ff  dry  Prediction\n",
              "0   Email 1    0   0    1    0  ...         0         0   0    0           0\n",
              "1   Email 2    8  13   24    6  ...         0         0   1    0           0\n",
              "2   Email 3    0   0    1    0  ...         0         0   0    0           0\n",
              "3   Email 4    0   5   22    0  ...         0         0   0    0           0\n",
              "4   Email 5    7   6   17    1  ...         0         0   1    0           0\n",
              "\n",
              "[5 rows x 3002 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNaAnjpONAs0",
        "outputId": "a7245079-6cc8-461a-f940-cc6b1b986bed"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "data = data[650:]\n",
        "X = data.drop(columns=['Prediction', 'Email No.'])\n",
        "y = data['Prediction']\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(X)\n",
        "X = x_scaled\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.53982301 0.54117647 0.02915452 ... 0.         0.07142857 0.        ]\n",
            " [0.10619469 0.12941176 0.0058309  ... 0.         0.         0.        ]\n",
            " [0.00884956 0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.01769912 0.08235294 0.         ... 0.         0.01190476 0.        ]\n",
            " [0.19469027 0.28235294 0.01166181 ... 0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzpJCBhE4RTe",
        "outputId": "dc113a88-d0b1-428a-ec3b-dd126808ba5a"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4522 entries, 650 to 5171\n",
            "Columns: 3002 entries, Email No. to Prediction\n",
            "dtypes: int64(3001), object(1)\n",
            "memory usage: 103.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j3_F8F4GWb6"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data.drop(columns=['Prediction', 'Email No.']).values, data['Prediction'], test_size=0.33, random_state=42)\n",
        "y_train = np.asarray(y_train)\n",
        "x_train = np.asarray(x_train)\n",
        "y_test = np.asarray(y_test)\n",
        "x_test = np.asarray(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zWYIeIHGc2V",
        "outputId": "5c3f381b-5c66-40a7-d258-66256526ae30"
      },
      "source": [
        "\n",
        "Check = LogisticRegression()\n",
        "Check.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOgkcD8gGl0_",
        "outputId": "b4c4d69d-8bf9-44f0-f9e9-c9ea533be6a5"
      },
      "source": [
        "accuracy = Check.score(x_test,y_test)\n",
        "y_pred_test = Check.predict(x_test)\n",
        "print(metrics.classification_report(y_test, y_pred_test))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      1060\n",
            "           1       0.93      0.96      0.95       433\n",
            "\n",
            "    accuracy                           0.97      1493\n",
            "   macro avg       0.96      0.97      0.96      1493\n",
            "weighted avg       0.97      0.97      0.97      1493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7ebopnujecL"
      },
      "source": [
        "Создадим свою модель логистической регрессии"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekPqzYRyjY1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9771da8d-7f70-4d17-b895-4f0822862f04"
      },
      "source": [
        "W = np.zeros(x_train.shape[1])\n",
        "b = 0\n",
        "\n",
        "def fit(X, Y,lr, iters):\n",
        "    X1, Y1 = X.copy(), Y.copy()\n",
        "    n = X.shape[0]\n",
        "    W = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "    for i in range(iters):\n",
        "        y_predicted = 1 / (1 + np.exp(-(np.dot(X1, W) + b)))\n",
        "        W -= lr * ((1 / n) * np.dot(X.T, y_predicted - Y1))\n",
        "        b -= lr * ((1 / n) * np.sum(y_predicted - Y))\n",
        "\n",
        "def predict(X):\n",
        "    probabilities = np.array(1 / (1 + np.exp(-(np.dot(X, W) + b))))\n",
        "    y_pred = np.where(probabilities >= 0.5, 1, 0)\n",
        "    return y_pred\n",
        "    \n",
        "x_train, x_test, y_train, y_test = train_test_split(data.drop(columns=['Prediction', 'Email No.']).values, data['Prediction'], test_size=0.33, random_state=42)\n",
        "y_train = np.asarray(y_train)\n",
        "x_train = np.asarray(x_train)\n",
        "y_test = np.asarray(y_test)\n",
        "x_test = np.asarray(x_test)\n",
        "\n",
        "x_train1 = np.apply_along_axis(lambda x: x/ x.std(), 0, x_train)\n",
        "x_test1 = np.apply_along_axis(lambda x: x/ x.std(), 0, x_test)\n",
        "fit(x_train1, y_train, 0.00001, 10000)\n",
        "y_pred_test = predict(x_test1)\n",
        "print(metrics.classification_report(y_test, y_pred_test))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83      1060\n",
            "           1       0.00      0.00      0.00       433\n",
            "\n",
            "    accuracy                           0.71      1493\n",
            "   macro avg       0.35      0.50      0.42      1493\n",
            "weighted avg       0.50      0.71      0.59      1493\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUTXrmhkjihw"
      },
      "source": [
        "Теперь протестируем ее"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_fJ57n5xBzC"
      },
      "source": [
        "Перейдем к решению задачи через Дерево Решений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY8d6sOczMS5",
        "outputId": "9e17a7b6-7c54-46b0-ce0d-deb866c1a53f"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "classifier = DecisionTreeClassifier()\n",
        "classifier = classifier.fit(x_train, y_train)\n",
        "# predict\n",
        "y_pred = classifier.predict(x_test)\n",
        "print(metrics.classification_report(y_test, y_pred))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95      1060\n",
            "           1       0.86      0.88      0.87       433\n",
            "\n",
            "    accuracy                           0.92      1493\n",
            "   macro avg       0.90      0.91      0.91      1493\n",
            "weighted avg       0.92      0.92      0.92      1493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYzWoz6J95ql"
      },
      "source": [
        "Теперь напишем свою реализацию Дерева Решений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzVDBNC986H"
      },
      "source": [
        "class Node():\n",
        "    def __init__(\n",
        "            self, \n",
        "            feature_index=None, \n",
        "            threshold=None, left=None,\n",
        "            right=None, \n",
        "            info_gain=None, \n",
        "            value=None):\n",
        "\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        self.value = value\n",
        "\n",
        "class decision_tree():\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "        self.root = None\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "    def build_tree(self, data, curr_depth=0):\n",
        "        X, Y = data[:,:-1], data[:,-1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "        \n",
        "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
        "            best_split = self.get_best_split(data, num_samples, num_features)\n",
        "            \n",
        "            if best_split['info_gain'] > 0:\n",
        "                left_subtree = self.build_tree(best_split['data_left'], curr_depth + 1)\n",
        "                right_subtree = self.build_tree(best_split['data_right'], curr_depth + 1)\n",
        "                return Node(best_split['feature_index'], best_split['threshold'], left_subtree, right_subtree, best_split['info_gain'])\n",
        "        \n",
        "        leaf_value = max(list(Y), key=list(Y).count)\n",
        "        return Node(value=leaf_value)\n",
        "    \n",
        "    def get_best_split(self, data, num_samples, num_features):\n",
        "        best_split = {}\n",
        "        max_info_gain = -float('inf')\n",
        "        \n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = data[:, feature_index]\n",
        "            for threshold in np.unique(feature_values):\n",
        "                data_left, data_right = self.split(data, feature_index, threshold)\n",
        "                if len(data_left) > 0 and len(data_right) > 0:\n",
        "                    y, left_y, right_y = data[:, -1], data_left[:, -1], data_right[:, -1]\n",
        "                    curr_info_gain = self.info_gain(y, left_y, right_y)\n",
        "                    \n",
        "                    if curr_info_gain > max_info_gain:\n",
        "                        best_split['feature_index'] = feature_index\n",
        "                        best_split['threshold'] = threshold\n",
        "                        best_split['data_left'] = data_left\n",
        "                        best_split['data_right'] = data_right\n",
        "                        best_split['info_gain'] = curr_info_gain\n",
        "                        max_info_gain = curr_info_gain\n",
        "        return best_split\n",
        "    \n",
        "\n",
        "    def split(self, data, i, border):\n",
        "        data_left = np.array([row for row in data if row[i] <= border])\n",
        "        data_right = np.array([row for row in data if row[i] > border])\n",
        "        return data_left, data_right\n",
        "    \n",
        "    def info_gain(self, parent, l_child, r_child):\n",
        "        weight_l = len(l_child) / len(parent)\n",
        "        weight_r = len(r_child) / len(parent)\n",
        "        return self.entropy(parent) - (weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child))\n",
        "    \n",
        "    def entropy(self, y):\n",
        "        class_labels = np.unique(y)\n",
        "        entropy = 0\n",
        "        for c in class_labels:\n",
        "            p = len(y[y == c]) / len(y)\n",
        "            entropy += -p * np.log2(p)\n",
        "        return entropy\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.root = self.build_tree(np.concatenate((X, Y), axis=1))\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return [self.prediction(x, self.root) for x in X]\n",
        "\n",
        "    def prediction(self, x, tree):\n",
        "        if tree.value != None: \n",
        "            return tree.value\n",
        "        else:\n",
        "            feature_val = x[tree.feature_index]\n",
        "            if feature_val<=tree.threshold:\n",
        "                return self.prediction(x, tree.left)\n",
        "            else:\n",
        "                return self.prediction(x, tree.right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SYGjZfn9-CL",
        "outputId": "fe427e79-2cc1-41dc-e3d6-b6b04c6cc3e7"
      },
      "source": [
        "params = [\n",
        "    (2, 1),\n",
        "    (2, 2),\n",
        "    (2, 3),\n",
        "    (2, 4),\n",
        "    (3, 1),\n",
        "    (3, 2),\n",
        "    (3, 3),\n",
        "    (3, 4),\n",
        "    (4, 1),\n",
        "    (4, 2),\n",
        "    (4, 3),\n",
        "    (4, 4)\n",
        "]\n",
        "\n",
        "min_samples_split, max_depth = 2,1\n",
        "mytree = decision_tree(min_samples_split, max_depth)\n",
        "mytree.fit(pd.DataFrame(x_train), pd.DataFrame(y_train))\n",
        "print(metrics.classification_report(y_test, mytree.predict(x_test)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.59      0.74      1060\n",
            "           1       0.50      1.00      0.66       433\n",
            "\n",
            "    accuracy                           0.71      1493\n",
            "   macro avg       0.75      0.79      0.70      1493\n",
            "weighted avg       0.85      0.71      0.72      1493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bCKeRfd5uek"
      },
      "source": [
        "Мы видим довольно низкую точность, поменяем параметры дерева"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qkGYObm5zH0",
        "outputId": "1f7650bc-cbb2-4c2e-d68d-e0e711a008fa"
      },
      "source": [
        "min_samples_split, max_depth = 3,4\n",
        "mytree = decision_tree(min_samples_split, max_depth)\n",
        "mytree.fit(pd.DataFrame(x_train), pd.DataFrame(y_train))\n",
        "print(metrics.classification_report(y_test, mytree.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.97      0.90      1060\n",
            "           1       0.89      0.55      0.68       433\n",
            "\n",
            "    accuracy                           0.85      1493\n",
            "   macro avg       0.87      0.76      0.79      1493\n",
            "weighted avg       0.86      0.85      0.84      1493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De1cAFoXDZQ-"
      },
      "source": [
        "Мы добились увеличения точности за счет увеличения глубины дерева"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je2vRHiY6VaE"
      },
      "source": [
        "class SVM_implementation:\n",
        "    def __init__(self, lr, lambda_, iters):\n",
        "        self.lr = lr\n",
        "        self.lambda_ = lambda_\n",
        "        self.iters = iters\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        n = X_train.shape[0]\n",
        "        self.W = np.zeros(X.shape[1])\n",
        "        self.b = 0\n",
        "        y_ = np.where(y <= 0, -1, 1)\n",
        "\n",
        "        for i in range(self.iters):\n",
        "            for j, x in enumerate(X_train):\n",
        "                if y_[j] * ((x @ self.W) - self.b) >= 1:\n",
        "                    self.W -= self.lr * (2 * self.lambda_ * self.W)\n",
        "                else:\n",
        "                    self.W -= self.lr * (2 * self.lambda_ * self.W - np.dot(x,y_[j]))\n",
        "                    self.b -= self.lr * y_[j]\n",
        "\n",
        "    def predict(self, X):\n",
        "        res = np.dot(X, self.W) - self.b\n",
        "        y_pred = np.where(res >= 0, 1, 0)\n",
        "        return y_pred\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v__nryOUAPUZ",
        "outputId": "691e95f1-fd54-432c-e1ef-011625bcb728"
      },
      "source": [
        "\n",
        "lr, lambda_, iters = 0.01, 0.01, 5000\n",
        "my_svm = SVM_implementation(lr=lr, lambda_=lambda_, iters=iters)\n",
        "my_svm.fit(x_train, y_train)\n",
        "print(metrics.classification_report(y_test, my_svm.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.91      0.81      1060\n",
            "           1       0.45      0.18      0.25       433\n",
            "\n",
            "    accuracy                           0.70      1493\n",
            "   macro avg       0.59      0.54      0.53      1493\n",
            "weighted avg       0.65      0.70      0.65      1493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVvjaCeYOq6h"
      },
      "source": [
        "Мы видим, что точность составила 59 процентов. Теперь опробуем поменять параметры"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUwve8ucGWMO",
        "outputId": "7b70cdae-9ddd-4347-a68a-7a37e597d0ab"
      },
      "source": [
        "lr, lambda_, iters = 0.001, 0.01, 5000\n",
        "my_svm = SVM_implementation(lr=lr, lambda_=lambda_, iters=iters)\n",
        "my_svm.fit(x_train, y_train)\n",
        "print(metrics.classification_report(y_test, my_svm.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.94      0.81      1060\n",
            "           1       0.31      0.07      0.11       433\n",
            "\n",
            "    accuracy                           0.69      1493\n",
            "   macro avg       0.51      0.50      0.46      1493\n",
            "weighted avg       0.60      0.69      0.61      1493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ig9Fbp7IvDN",
        "outputId": "1866cab8-c3a7-4add-a585-483d9f92262f"
      },
      "source": [
        "lr, lambda_, iters = 0.01, 0.01, 10000\n",
        "my_svm = SVM_implementation(lr=lr, lambda_=lambda_, iters=iters)\n",
        "my_svm.fit(x_train, y_train)\n",
        "print(metrics.classification_report(y_test, my_svm.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.78      0.74      1060\n",
            "           1       0.26      0.19      0.22       433\n",
            "\n",
            "    accuracy                           0.61      1493\n",
            "   macro avg       0.48      0.48      0.48      1493\n",
            "weighted avg       0.57      0.61      0.59      1493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x5TLxrNOv20",
        "outputId": "b82925bc-75ed-4e37-deec-1f55c9bb8f2a"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "sklearn_svm_model = SVC()\n",
        "sklearn_svm_model.fit(x_train, y_train)\n",
        "y_pred = sklearn_svm_model.predict(x_test)\n",
        "print(metrics.classification_report(y_test, y_pred)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.98      0.87      1060\n",
            "           1       0.85      0.33      0.48       433\n",
            "\n",
            "    accuracy                           0.79      1493\n",
            "   macro avg       0.82      0.65      0.67      1493\n",
            "weighted avg       0.80      0.79      0.75      1493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4TcUdkOXRkh"
      },
      "source": [
        "Мы видим, что библиотечная реализация является эффективней"
      ]
    }
  ]
}